{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check environment\n",
    "\n",
    "This notebook will help verify the installed Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version 1.13.3 is OK\n",
      "matplotlib version 2.0.2 is OK\n",
      "pandas version 0.20.2 is OK\n",
      "nltk version 3.2.4 is OK\n",
      "tensorflow version 1.3.0 is OK\n"
     ]
    }
   ],
   "source": [
    "# Version checks\n",
    "import importlib\n",
    "def version_check(libname, min_version):\n",
    "    m = importlib.import_module(libname)\n",
    "    print(\"{} version {} is \".format(libname, m.__version__), end='')\n",
    "    print(\"OK\" if m.__version__ >= min_version \n",
    "           else \"out-of-date. Please upgrade!\")\n",
    "    \n",
    "version_check(\"numpy\", \"1.12\")\n",
    "version_check(\"matplotlib\", \"2.0\")\n",
    "version_check(\"pandas\", \"0.20\")\n",
    "version_check(\"nltk\", \"3.2\")\n",
    "version_check(\"tensorflow\", \"1.1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "\n",
    "Quick [TensorFlow](tensorflow.org) test, verifying that it loads correctly.\n",
    "\n",
    "Run the cell below; you should see:\n",
    "```\n",
    "Hello, TensorFlow!\n",
    "42\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(sess.run(a+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following warnings are examples (in jupyter console) which indicate that HW support is available but not enabled:\n",
    "\n",
    "```\n",
    "[W tensorflow/core/platform/cpu_feature_guard.cc:45]\n",
    "The TensorFlow library wasn't compiled to use the following, but these are available on your machine and could speed up CPU computations:\n",
    "*  SSE4.1 instructions\n",
    "*  SSE4.2 instructions\n",
    "*  AVX instructions\n",
    "*  AVX2 instructions\n",
    "*  FMA instructions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "```\n",
    "2017-09-26 11:37:10.712614: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-09-26 11:37:10.712671: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-09-26 11:37:10.712688: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "\n",
    "[NLTK](http://www.nltk.org/) is a large compilation of Python NLP packages. \n",
    "\n",
    "NLTK is included with Anaconda, but the corpora need to be downloaded separately. Be warned that this will take up around 3.2 GB of disk space if you download everything! If this is too much, you can download individual corpora as you need them through the same interface.\n",
    "\n",
    "The following will pop-up UI with the downloader:\n",
    "\n",
    "```\n",
    "import nltk\n",
    "nltk.download()\n",
    "```\n",
    "\n",
    "The following will download everything with no GUI (optionally run via sudo in a multi-user environment, so the data is centrally available):\n",
    "\n",
    "```\n",
    "sudo python3 -m nltk.downloader -d /usr/share/nltk_data  all\n",
    "```\n",
    "\n",
    "Alternatively, you can download individual corpora by name. The cell below will download the famous [Brown corpus](http://www.essex.ac.uk/linguistics/external/clmt/w3c/corpus_ling/content/corpora/list/private/brown/brown.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/michael/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "assert(nltk.download(\"brown\"))  # should return True if successful, or already installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at a few sentences. Expect to see:\n",
    "```\n",
    "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
    "\n",
    "The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\n",
      "\n",
      "The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "# Look at the first two sentences\n",
    "for s in brown.sents()[:2]:\n",
    "    print(\" \".join(s))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK also includes a sample of the [Penn treebank](https://www.cis.upenn.edu/~treebank/), which we'll be using later in the course for parsing and part-of-speech tagging. Here's a sample of sentences, and an example tree. Expect to see:\n",
    "```\n",
    "The top money funds are currently yielding well over 9 % .\n",
    "\n",
    "(S\n",
    "  (NP-SBJ (DT The) (JJ top) (NN money) (NNS funds))\n",
    "  (VP\n",
    "    (VBP are)\n",
    "    (ADVP-TMP (RB currently))\n",
    "    (VP (VBG yielding) (NP (QP (RB well) (IN over) (CD 9)) (NN %))))\n",
    "  (. .))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /home/michael/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "\n",
      "The top money funds are currently yielding well over 9 % .\n",
      "\n",
      "(S\n",
      "  (NP-SBJ (DT The) (JJ top) (NN money) (NNS funds))\n",
      "  (VP\n",
      "    (VBP are)\n",
      "    (ADVP-TMP (RB currently))\n",
      "    (VP (VBG yielding) (NP (QP (RB well) (IN over) (CD 9)) (NN %))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "assert(nltk.download(\"treebank\"))  # should return True if successful, or already installed\n",
    "print(\"\")\n",
    "from nltk.corpus import treebank\n",
    "# Look at the parse of a sentence.\n",
    "# Don't worry about what this means yet!\n",
    "idx = 45\n",
    "print(\" \".join(treebank.sents()[idx]))\n",
    "print(\"\")\n",
    "print(treebank.parsed_sents()[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the [Europarl corpus](http://www.statmt.org/europarl/), which consists of *parallel* text - a sentence and its translations to multiple languages. You should see:\n",
    "```\n",
    "ENGLISH: Resumption of the session I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999 , and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period .\n",
    "```\n",
    "and its translation into French and Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package europarl_raw to\n",
      "[nltk_data]     /home/michael/nltk_data...\n",
      "[nltk_data]   Package europarl_raw is already up-to-date!\n",
      "\n",
      "ENGLISH: Resumption of the session I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999 , and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period .\n",
      "\n",
      "FRENCH: Reprise de la session Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances .\n",
      "\n",
      "SPANISH: Reanudación del período de sesiones Declaro reanudado el período de sesiones del Parlamento Europeo , interrumpido el viernes 17 de diciembre pasado , y reitero a Sus Señorías mi deseo de que hayan tenido unas buenas vacaciones .\n"
     ]
    }
   ],
   "source": [
    "assert(nltk.download(\"europarl_raw\"))  # should return True if successful, or already installed\n",
    "print(\"\")\n",
    "from nltk.corpus import europarl_raw\n",
    "\n",
    "idx = 0\n",
    "\n",
    "print(\"ENGLISH: \" + \" \".join(europarl_raw.english.sents()[idx]))\n",
    "print(\"\")\n",
    "print(\"FRENCH: \" + \" \".join(europarl_raw.french.sents()[idx]))\n",
    "print(\"\")\n",
    "print(\"SPANISH: \" + \" \".join(europarl_raw.spanish.sents()[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42.]\n",
      "[ 4.  6.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "if os.path.isdir(\"../code/util/\"):\n",
    "    os.chdir('../code')\n",
    "\n",
    "from util import graph, graph_test\n",
    "reload(graph)\n",
    "reload(graph_test)\n",
    "\n",
    "adder = graph.AddTwo()  # Internally, creates tf.Graph and tf.Session\\n\"\n",
    "print(adder.Add(40, 2))\n",
    "print(adder.Add([1,2],[3,4]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
